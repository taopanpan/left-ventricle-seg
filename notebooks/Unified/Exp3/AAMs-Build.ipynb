{
 "metadata": {
  "name": "",
  "signature": "sha256:671c740c305c99698c74f7350f7af15bd3eec4d4e37046f27be052c6d82c737e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.landmark import labeller, lfpw_face\n",
      "from menpofast.utils import convert_from_menpo\n",
      "\n",
      "path = '/data/'\n",
      "group = 'lfpw_face'\n",
      "\n",
      "training_images = []\n",
      "for i in mio.import_images(path + 'PhD/DataBases/faces/cofw/trainset/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.visualize import visualize_images\n",
      "\n",
      "visualize_images(training_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Active Appearance Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build and Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofast.feature import no_op, fast_dsift\n",
      "from alabortcvpr2015.aam import PartsAAMBuilder\n",
      "\n",
      "unified = PartsAAMBuilder(parts_shape=(21, 21),\n",
      "                          features=fast_dsift,\n",
      "                          diagonal=100,\n",
      "                          normalize_parts=False,\n",
      "                          scales=(1, .5),\n",
      "                          max_shape_components=25,\n",
      "                          max_appearance_components=500).build(training_images,\n",
      "                                                               group=group,\n",
      "                                                               verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofast.image import Image\n",
      "\n",
      "Image(unified.appearance_models[0].mean().pixels[18, 0]).view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alabortcvpr2015.utils import pickle_dump\n",
      "\n",
      "pickle_dump(unified, path + 'PhD/Models/aam_cofw_fast_dsift')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "os.chdir('../..')\n",
    "\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import menpo.io as mio\n",
    "import tensorflow as tf\n",
    "from menpo.visualize import print_progress\n",
    "\n",
    "from menpowidgets import visualize_images\n",
    "from project.utils import tfrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TFRecords files\n",
    "\n",
    "The recommended format for TensorFlow is a TFRecords file containing `tf.train.Example` protocol buffers (which contain `Features` as a field).\n",
    "\n",
    "Here is a little program that gets your data, stuffs it in an `Example` protocol buffer, serializes the protocol buffer to a string, and then writes the string to a TFRecords file using the `tf.python_io.TFRecordWriter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def face_iterator(images):\n",
    "    \"\"\" Given an iterable of images, returns a generator of cat face data \"\"\"\n",
    "    for idx, img in enumerate(print_progress(images, end_with_newline=False)):\n",
    "        image_name = 'frame_{}'.format(idx)\n",
    "\n",
    "        yield image_name, img\n",
    "\n",
    "\n",
    "def generate(iterator,\n",
    "             store_path='./',\n",
    "             record_name='inference.tfrecords',\n",
    "             store_records=True):\n",
    "    store_path = Path(store_path)\n",
    "\n",
    "    if store_records:\n",
    "        writer = tf.python_io.TFRecordWriter(str(store_path / record_name))\n",
    "\n",
    "    for img_name, pimg in iterator:\n",
    "        \n",
    "        # resize image to 256 * 256\n",
    "        cimg = pimg.resize([256, 256])\n",
    "\n",
    "        img_path = store_path / '{}'.format(img_name)\n",
    "\n",
    "        if store_records:\n",
    "            try:\n",
    "                # construct the Example proto object\n",
    "                example = tf.train.Example(\n",
    "                    features=tf.train.Features(\n",
    "                        # Features contains a map of string to Feature proto objects\n",
    "                        feature={\n",
    "                            # images\n",
    "                            'image': tfrecords.jpg_feature(cimg),\n",
    "                            'height': tfrecords.int_feature(cimg.shape[0]),\n",
    "                            'width': tfrecords.int_feature(cimg.shape[1]),\n",
    "                        }))\n",
    "                # use the proto object to serialize the example to a string\n",
    "                serialized = example.SerializeToString()\n",
    "                # write the serialized object to disk\n",
    "                writer.write(serialized)\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Something bad happened when processing image: \"{}\"'.format(img_name))\n",
    "                print(e)\n",
    "\n",
    "    if store_records:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TFRecords for Inference\n",
    "\n",
    "Run the following cells to generate TFRecords for a directory of images to perform inference on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where are the images located?\n",
    "video_dir = Path('D:/dev/project/data/ibug/cats/videos')\n",
    "video_name = 'video6.mp4'\n",
    "\n",
    "video_path = video_dir / video_name\n",
    "\n",
    "# where should the resulting TFRecords files be written to?\n",
    "store_path = Path('data/tfrecords/inference')\n",
    "inference_record_name = Path(video_path.stem + '.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to generate the TFRecord file!\n",
    "\n",
    "# load the images\n",
    "images = mio.import_video(video_path)\n",
    "\n",
    "print('Found {} assets'.format(len(images)))\n",
    "\n",
    "# generate TFRecords\n",
    "generate(face_iterator(images), store_path, inference_record_name,\n",
    "         store_records=True)\n",
    "\n",
    "print('Created {}'.format(store_path / inference_record_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(images, browser_style ='slider')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

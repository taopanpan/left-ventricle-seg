{
 "metadata": {
  "name": "",
  "signature": "sha256:ae48140e044c746267c70b5db6a63ca1560c80d5c1d365a3c169380a7af130a6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.landmark import labeller, ibug_face_49\n",
      "from menpofast.utils import convert_from_menpo\n",
      "\n",
      "path = '/data/'\n",
      "group = 'ibug_face_49'\n",
      "\n",
      "training_images = []\n",
      "for i in mio.import_images(path + 'PhD/DataBases/faces/lfpw/trainset/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group='PTS')\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in mio.import_images(path + 'PhD/DataBases/faces/helen/trainset/',\n",
      "                           verbose=True, max_images=2000):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group='PTS')\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in mio.import_images(path + 'PhD/DataBases/faces/ibug/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group='PTS')\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.visualize import visualize_images\n",
      "\n",
      "visualize_images(training_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Unified HDMs and PBDMs"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build and Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofast.feature import no_op, fast_dsift\n",
      "from alabortcvpr2015.unified import PartsUnifiedBuilder\n",
      "from alabortcvpr2015.utils import pickle_dump\n",
      "\n",
      "#n_images = [pow(2,i) for i in range(5, 12)]\n",
      "\n",
      "#for j, limit in enumerate(n_images):\n",
      "\n",
      "#    unified = PartsUnifiedBuilder(parts_shape=(17, 17),\n",
      "#                                  features=fast_dsift,\n",
      "#                                  diagonal=100,\n",
      "#                                  normalize_parts=False,\n",
      "#                                  covariance=3,\n",
      "#                                  scales=(1, .5),\n",
      "#                                  max_shape_components=25,\n",
      "#                                  max_appearance_components=500).build(training_images[:limit],\n",
      "#                                                                       group=group,\n",
      "#                                                                       verbose=True)\n",
      "\n",
      "#    pickle_dump(unified, path + 'PhD/Models/unified_lfpw_fast_dsift' + str(j))\n",
      "\n",
      "#    del unified\n",
      "    \n",
      "unified = PartsUnifiedBuilder(parts_shape=(17, 17),\n",
      "                              features=fast_dsift,\n",
      "                              diagonal=100,\n",
      "                              normalize_parts=False,\n",
      "                              covariance=3,\n",
      "                              scales=(1, .5),\n",
      "                              max_shape_components=25,\n",
      "                              max_appearance_components=500).build(training_images,\n",
      "                                                                   group=group,\n",
      "                                                                   verbose=True)\n",
      "\n",
      "pickle_dump(unified, path + 'PhD/Models/unified_lfpw_fast_dsift' + str(7))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
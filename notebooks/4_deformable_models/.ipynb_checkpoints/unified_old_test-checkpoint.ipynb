{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "os.chdir('../..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.landmark import labeller, left_ventricle_34,left_ventricle_34_trimesh,left_ventricle_34_trimesh1\n",
    "\n",
    "from menpo.transform import ThinPlateSplines\n",
    "from menpo.feature import *\n",
    "from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "from menpofit.fitter import noisy_shape_from_bounding_box\n",
    "from menpofit.visualize import plot_cumulative_error_distribution\n",
    "from menpowidgets import *\n",
    "from menpodetect import load_dlib_left_ventricle_detector\n",
    "from menpo.io import export_pickle,import_pickle\n",
    "from menpo.visualize import print_progress\n",
    "import menpo.visualize\n",
    "\n",
    "import project.utils.labeller_lv as labels\n",
    "from project.utils import tfrecords\n",
    "import predict_lv as predict\n",
    "import project.utils.visualisation as visualisation\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import skimage.io as io\n",
    "from io import BytesIO\n",
    "from IPython.display import Image\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# method to load a database\n",
    "def load_database(path_to_images, crop_percentage,max_diagonal=400, max_images=None):\n",
    "    images = []\n",
    "    # load landmarked images\n",
    "    for i in mio.import_images(path_to_images, max_images=max_images, verbose=True):\n",
    "           \n",
    "        # convert it to grayscale if needed\n",
    "        if i.n_channels == 3:\n",
    "            i = i.as_greyscale(mode='luminosity')\n",
    "        # crop image\n",
    "        i = i.crop_to_landmarks_proportion(crop_percentage)\n",
    "        \n",
    "        d = i.diagonal()\n",
    "        if d > max_diagonal:\n",
    "            i = i.rescale(float(max_diagonal) / d)\n",
    "        # define a TriMesh which will be useful for Piecewise Affine Warp of HolisticAAM\n",
    "        \n",
    "        labeller(i, 'PTS', left_ventricle_34)#lv_34_trimesh\n",
    "        labeller(i, 'PTS', left_ventricle_34_trimesh1)\n",
    "        labeller(i, 'PTS', left_ventricle_34_trimesh)\n",
    "        #i= i.resize([256, 256])\n",
    "        # append it to the list\n",
    "        images.append(i)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_evaluation_master': '', '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      ", '_task_id': 0, '_master': '', '_environment': 'local', '_task_type': None, '_is_chief': True, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 0, '_model_dir': 'models\\\\lv\\\\lv_1hg_lr1e-3_decay10', '_save_summary_steps': 100, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025F249672B0>, '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "# hg 特征\n",
    "from project.hourglass import estimator\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.core.protobuf import config_pb2\n",
    "from menpo.feature import *\n",
    "import project.hourglass.params as hgparams\n",
    "from tensorflow.python.estimator.inputs import numpy_io \n",
    "\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow.python.training import queue_runner_impl\n",
    "\n",
    "from skimage import transform \n",
    "params = {\n",
    "    hgparams.N_FEATURES: 128,\n",
    "    hgparams.N_HOURGLASS: 1,\n",
    "    hgparams.N_RESIDUALS: 3,\n",
    "}\n",
    "# Where is the model located?\n",
    "model_dir = Path('models/lv/lv_1hg_lr1e-3_decay10/')\n",
    "params[hgparams.N_LANDMARKS] = 34\n",
    "# Instantiate Estimator\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "    gpu_memory_fraction=1, session_config=config)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        nn = learn.Estimator(\n",
    "        model_dir=str(model_dir),\n",
    "        params=params,\n",
    "        config=run_config,\n",
    "        model_fn=estimator._model_fn)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "@ndfeature\n",
    "def hg(image):\n",
    "    _,h,w= image.shape\n",
    "    image = image.reshape([w,h])\n",
    "    image=transform.resize(image, (256, 256))\n",
    "    image = image.reshape([1,256,256])\n",
    "    data = np.zeros((1, 256, 256, 3), np.float32)  \n",
    "    data[:,:, :, 0] = image\n",
    "    data[:,:, :, 1] = image\n",
    "    data[:,:, :, 2] = image\n",
    "    data=data.astype(np.float32)\n",
    "    #image=image/255.0\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "          x={\"image\": data},\n",
    "          num_epochs=1,\n",
    "          shuffle=False)\n",
    "        predictions = nn.predict(input_fn=input_fn)\n",
    "        images_generator = visualisation.lv_predictions(predictions,\n",
    "                                                    show_input_images=False,\n",
    "                                                    show_combined_heatmap=True,\n",
    "                                                    show_individual_heatmaps=False)\n",
    "\n",
    "    images = menpo.base.LazyList.init_from_iterable(images_generator)\n",
    "\n",
    "    def flatten(list_of_lists): return [\n",
    "        item for sublist in list_of_lists for item in sublist]\n",
    "    images = flatten(images)\n",
    "    images[0] =images[0].resize([w, h]).rescale_pixels(0, 255.0)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    return images[0].pixels\n",
    "def hog_closure(image):\n",
    "    return hog(image,cell_size=4, window_step_horizontal=1, window_step_vertical=1)\n",
    "\n",
    "#hg(train_images[1])\n",
    "#type(train_images[1])\n",
    "#hg(train_images[4])\n",
    "#visualize_images(hg(train_images[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the AAM on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 assets, index the returned LazyList to import.\n"
     ]
    }
   ],
   "source": [
    "max_images = 167\n",
    "test_images =load_database('data/images',crop_percentage=0.5,max_images=max_images)\n",
    "#test_images = test_images[-70:]\n",
    "\n",
    "#visualize_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\develop\\menpo-py3\\menpo\\shape\\pointcloud.py:261: MenpoDeprecationWarning: The .lms property is deprecated. LandmarkGroups are now shapes themselves - so you can use them directly anywhere you previously used .lms.Simply remove \".lms\" from your code and things will work as expected (and this warning will go away)\n",
      "  MenpoDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0,'I:/menpo/project_lv' ) \n",
    "\n",
    "unified_path = Path('I:/menpo/project_lv/data/deformable/unified/no-op-unified.pkl')\n",
    "\n",
    "if unified_path.exists():\n",
    "    unified = mio.import_pickle(unified_path)\n",
    "    print('load done')\n",
    "\n",
    "from alabortcvpr2015.unified import GlobalUnifiedFitter, AICRLMS\n",
    "\n",
    "fitter = GlobalUnifiedFitter(unified, algorithm_cls=AICRLMS, n_shape=[3, 12],\n",
    "                            n_appearance=[25, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpofit.fitter import noisy_shape_from_shape\n",
    "\n",
    "detector=load_dlib_left_ventricle_detector(\"detector.svm\")\n",
    "def test():        \n",
    "    fitting_results = []\n",
    "    \n",
    "    for image in print_progress(test_images):\n",
    "        \n",
    "        gt_shape = image.landmarks['PTS']\n",
    "        bboxes = detector(image)\n",
    "        #print(\"{} detected .\".format(len(bboxes)))\n",
    "        initial_bbox = bboxes[0]\n",
    "        #tf.reset_default_graph()\n",
    "       # result = fitter.fit_from_bb(image,  initial_bbox, max_iters=25, gt_shape=gt_shape, return_costs=True )\n",
    "        initial_shape = noisy_shape_from_shape(fitter.reference_shape, gt_shape,noise_percentage=0.06)\n",
    "\n",
    "        result = fitter.fit(image, initial_shape, max_iters=40, gt_shape=gt_shape)#, return_costs=True\n",
    "        fitting_results.append(result)\n",
    "        \n",
    "    return fitting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                    ] 1% (3/167) - 00:02:38 remaining                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\develop\\menpo-py3\\menpo\\feature\\features.py:833: UserWarning: One or more the scale factors are 0.0 and thus theseentries will be skipped during normalization.\n",
      "  warnings.warn('One or more the scale factors are 0.0 and thus these'\n",
      "I:/menpo/project_lv\\alabortcvpr2015\\clm\\classifier.py:95: RuntimeWarning: invalid value encountered in true_divide\n",
      "  axis=(-2, -1))[..., None, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100% (167/167) - done.                                   \n"
     ]
    }
   ],
   "source": [
    "test_path = Path('data/deformable/clm/no-op-holistic-unified-testresults.pkl')\n",
    "\n",
    "if test_path.exists():\n",
    "    test_results = mio.import_pickle(test_path)\n",
    "else:\n",
    "    test_results = test()\n",
    "    mio.export_pickle(test_results, test_path, overwrite=True, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpowidgets import plot_ced\n",
    "\n",
    "# Plot fitting error over test data (Cumulative Error Distribution)\n",
    "\n",
    "initial_errors = [r.initial_error() for r in test_results]\n",
    "final_errors = [r.final_error() for r in test_results]\n",
    "\n",
    "plot_ced([initial_errors, final_errors], legend_entries=['Initial', 'Final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpowidgets import visualize_fitting_results \n",
    "visualize_fitting_results(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpo.image import Image\n",
    "#Image(np.real(np.fft.fftshift(np.fft.ifft2(clm.classifiers[0][36].f)))).view()\n",
    "#clm.view_expert_ensemble_widget()\n",
    "#clm.view_shape_models_widget()\n",
    "#clm.view_clm_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unified_path = Path('I:/menpo/project_lv/data/deformable/unified/no-op-patch-unified.pkl')\n",
    "\n",
    "if unified_path.exists():\n",
    "    unified = mio.import_pickle(unified_path)\n",
    "    print('load done')\n",
    "\n",
    "from alabortcvpr2015.unified import PartsUnifiedFitter, AICRLMS\n",
    "\n",
    "fitter = PartsUnifiedFitter(unified, algorithm_cls=AICRLMS, n_shape=[3, 12],\n",
    "                            n_appearance=[25, 50])\n",
    "\n",
    "test_path = Path('data/deformable/clm/no-op-patch-unified-testresults.pkl')\n",
    "\n",
    "if test_path.exists():\n",
    "    test_results = mio.import_pickle(test_path)\n",
    "else:\n",
    "    test_results = test()\n",
    "    mio.export_pickle(test_results, test_path, overwrite=True, protocol=2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

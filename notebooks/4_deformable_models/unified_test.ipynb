{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "os.chdir('../..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.landmark import labeller, left_ventricle_34,left_ventricle_34_trimesh,left_ventricle_34_trimesh1\n",
    "\n",
    "from menpo.transform import ThinPlateSplines\n",
    "from menpo.feature import *\n",
    "from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "from menpofit.fitter import noisy_shape_from_bounding_box\n",
    "from menpofit.visualize import plot_cumulative_error_distribution\n",
    "from menpowidgets import *\n",
    "from menpodetect import load_dlib_left_ventricle_detector\n",
    "from menpo.io import export_pickle,import_pickle\n",
    "from menpo.visualize import print_progress\n",
    "import menpo.visualize\n",
    "\n",
    "import project.utils.labeller_lv as labels\n",
    "from project.utils import tfrecords\n",
    "import predict_lv as predict\n",
    "import project.utils.visualisation as visualisation\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import skimage.io as io\n",
    "from io import BytesIO\n",
    "from IPython.display import Image\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# method to load a database\n",
    "def load_database(path_to_images, crop_percentage,max_diagonal=400, max_images=None):\n",
    "    images = []\n",
    "    # load landmarked images\n",
    "    for i in mio.import_images(path_to_images, max_images=max_images, verbose=True):\n",
    "           \n",
    "        # convert it to grayscale if needed\n",
    "        if i.n_channels == 3:\n",
    "            i = i.as_greyscale(mode='luminosity')\n",
    "        # crop image\n",
    "        i = i.crop_to_landmarks_proportion(crop_percentage)\n",
    "        \n",
    "        d = i.diagonal()\n",
    "        if d > max_diagonal:\n",
    "            i = i.rescale(float(max_diagonal) / d)\n",
    "        # define a TriMesh which will be useful for Piecewise Affine Warp of HolisticAAM\n",
    "        \n",
    "        labeller(i, 'PTS', left_ventricle_34)#lv_34_trimesh\n",
    "        labeller(i, 'PTS', left_ventricle_34_trimesh1)\n",
    "        labeller(i, 'PTS', left_ventricle_34_trimesh)\n",
    "        #i= i.resize([256, 256])\n",
    "        # append it to the list\n",
    "        images.append(i)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000281C9AF8358>, '_tf_random_seed': None, '_is_chief': True, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      ", '_task_type': None, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_save_checkpoints_steps': None, '_model_dir': 'models\\\\lv\\\\lv_1hg_lr1e-3_decay10', '_num_worker_replicas': 0, '_keep_checkpoint_max': 5, '_environment': 'local'}\n"
     ]
    }
   ],
   "source": [
    "# hg 特征\n",
    "from project.hourglass import estimator\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.core.protobuf import config_pb2\n",
    "from menpo.feature import *\n",
    "import project.hourglass.params as hgparams\n",
    "from tensorflow.python.estimator.inputs import numpy_io \n",
    "\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow.python.training import queue_runner_impl\n",
    "\n",
    "from skimage import transform \n",
    "params = {\n",
    "    hgparams.N_FEATURES: 128,\n",
    "    hgparams.N_HOURGLASS: 1,\n",
    "    hgparams.N_RESIDUALS: 3,\n",
    "}\n",
    "# Where is the model located?\n",
    "model_dir = Path('models/lv/lv_1hg_lr1e-3_decay10/')\n",
    "params[hgparams.N_LANDMARKS] = 34\n",
    "# Instantiate Estimator\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "    gpu_memory_fraction=1, session_config=config)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        nn = learn.Estimator(\n",
    "        model_dir=str(model_dir),\n",
    "        params=params,\n",
    "        config=run_config,\n",
    "        model_fn=estimator._model_fn)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "@ndfeature\n",
    "def hg(image):\n",
    "    _,h,w= image.shape\n",
    "    image = image.reshape([w,h])\n",
    "    image=transform.resize(image, (256, 256))\n",
    "    image = image.reshape([1,256,256])\n",
    "    data = np.zeros((1, 256, 256, 3), np.float32)  \n",
    "    data[:,:, :, 0] = image\n",
    "    data[:,:, :, 1] = image\n",
    "    data[:,:, :, 2] = image\n",
    "    data=data.astype(np.float32)\n",
    "    #image=image/255.0\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "          x={\"image\": data},\n",
    "          num_epochs=1,\n",
    "          shuffle=False)\n",
    "        predictions = nn.predict(input_fn=input_fn)\n",
    "        images_generator = visualisation.lv_predictions(predictions,\n",
    "                                                    show_input_images=False,\n",
    "                                                    show_combined_heatmap=True,\n",
    "                                                    show_individual_heatmaps=False)\n",
    "\n",
    "    images = menpo.base.LazyList.init_from_iterable(images_generator)\n",
    "\n",
    "    def flatten(list_of_lists): return [\n",
    "        item for sublist in list_of_lists for item in sublist]\n",
    "    images = flatten(images)\n",
    "    images[0] =images[0].resize([w, h]).rescale_pixels(0, 255.0)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    return images[0].pixels\n",
    "def hog_closure(image):\n",
    "    return hog(image,cell_size=4, window_step_horizontal=1, window_step_vertical=1)\n",
    "\n",
    "#hg(train_images[1])\n",
    "#type(train_images[1])\n",
    "#hg(train_images[4])\n",
    "#visualize_images(hg(train_images[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the AAM on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 assets, index the returned LazyList to import.\n"
     ]
    }
   ],
   "source": [
    "max_images = 167\n",
    "test_images =load_database('data/images',crop_percentage=0.5,max_images=max_images)\n",
    "#test_images = test_images[-70:]\n",
    "\n",
    "#visualize_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\develop\\menpo-py3\\menpo\\shape\\pointcloud.py:261: MenpoDeprecationWarning: The .lms property is deprecated. LandmarkGroups are now shapes themselves - so you can use them directly anywhere you previously used .lms.Simply remove \".lms\" from your code and things will work as expected (and this warning will go away)\n",
      "  MenpoDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0,'I:/menpo/project_lv' ) \n",
    "\n",
    "unified_path = Path('I:/menpo/project_lv/data/deformable/unified/no-op-unified1.pkl')\n",
    "\n",
    "if unified_path.exists():\n",
    "    unified = mio.import_pickle(unified_path)\n",
    "    print('load done')\n",
    "\n",
    "from menpofit.unified_aam_clm import UnifiedAAMCLMFitter\n",
    "fitter = UnifiedAAMCLMFitter(unified,n_shape=[5, 10,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpofit.fitter import noisy_shape_from_shape\n",
    "\n",
    "detector=load_dlib_left_ventricle_detector(\"detector.svm\")\n",
    "def test():        \n",
    "    fitting_results = []\n",
    "    \n",
    "    for image in print_progress(test_images):\n",
    "        \n",
    "        gt_shape = image.landmarks['PTS']\n",
    "        bboxes = detector(image)\n",
    "        #print(\"{} detected .\".format(len(bboxes)))\n",
    "        initial_bbox = bboxes[0]\n",
    "        #tf.reset_default_graph()\n",
    "       # result = fitter.fit_from_bb(image,  initial_bbox, max_iters=25, gt_shape=gt_shape, return_costs=True )\n",
    "        initial_shape = noisy_shape_from_shape(fitter.reference_shape, gt_shape,noise_percentage=0.05)\n",
    "\n",
    "        result = fitter.fit_from_shape(image, initial_shape, max_iters=10, gt_shape=gt_shape)#, return_costs=True\n",
    "        fitting_results.append(result)\n",
    "        \n",
    "    return fitting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\develop\\menpo-py3\\menpo\\shape\\pointcloud.py:261: MenpoDeprecationWarning: The .lms property is deprecated. LandmarkGroups are now shapes themselves - so you can use them directly anywhere you previously used .lms.Simply remove \".lms\" from your code and things will work as expected (and this warning will go away)\n",
      "  MenpoDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========          ] 53% (90/167) - 00:00:17 remaining                        "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-eb06d229c87f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtest_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtest_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-492499fd4326>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0minitial_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoisy_shape_from_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreference_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise_percentage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_from_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgt_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, return_costs=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mfitting_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpofit-py3\\menpofit\\fitter.py\u001b[0m in \u001b[0;36mfit_from_shape\u001b[1;34m(self, image, initial_shape, max_iters, gt_shape, return_costs, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m                                       \u001b[0mscale_transforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale_transforms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                                       \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgt_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m                                       return_costs=return_costs, **kwargs)\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[1;31m# Return multi-scale fitting result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpofit-py3\\menpofit\\fitter.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, images, initial_shape, affine_transforms, scale_transforms, gt_shapes, max_iters, return_costs, **kwargs)\u001b[0m\n\u001b[0;32m    471\u001b[0m                                                       \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                                                       \u001b[0mreturn_costs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_costs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m                                                       **kwargs)\n\u001b[0m\u001b[0;32m    474\u001b[0m             \u001b[1;31m# Add algorithm result to the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0malgorithm_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithm_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpofit-py3\\menpofit\\unified_aam_clm\\algorithm.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, image, initial_shape, gt_shape, max_iters, return_costs, prior, a)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;31m# CLM part --------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0me_clm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_clm_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# update costs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpofit-py3\\menpofit\\unified_aam_clm\\algorithm.py\u001b[0m in \u001b[0;36m_compute_clm_error\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# compute parts response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         parts_response = self.expert_ensemble.predict_probability(\n\u001b[1;32m---> 99\u001b[1;33m             image, target).squeeze()\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mparts_response\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparts_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpofit-py3\\menpofit\\clm\\expert\\ensemble.py\u001b[0m in \u001b[0;36mpredict_probability\u001b[1;34m(self, image, shape)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mresponses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# Turn them into proper probability maps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mprobability_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpo-py3\\menpo\\feature\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(image, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrebuild_feature_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\develop\\menpofit-py3\\menpofit\\clm\\expert\\base.py\u001b[0m in \u001b[0;36mprobability_map\u001b[1;34m(x, axes)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mnonzero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         warnings.warn('some of x axes have 0 variance - uniform probability '\n\u001b[0m\u001b[0;32m     29\u001b[0m                       'maps are used them.')\n\u001b[0;32m     30\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "test_path = Path('data/deformable/unified/no-op-holistic-unified1-testresults.pkl')\n",
    "\n",
    "if test_path.exists():\n",
    "    test_results = mio.import_pickle(test_path)\n",
    "else:\n",
    "    test_results = test()\n",
    "    mio.export_pickle(test_results, test_path, overwrite=True, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpowidgets import plot_ced\n",
    "\n",
    "# Plot fitting error over test data (Cumulative Error Distribution)\n",
    "\n",
    "initial_errors = [r.initial_error() for r in test_results]\n",
    "final_errors = [r.final_error() for r in test_results]\n",
    "\n",
    "plot_ced([initial_errors, final_errors], legend_entries=['Initial', 'Final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpowidgets import visualize_fitting_results \n",
    "visualize_fitting_results(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpo.image import Image\n",
    "#Image(np.real(np.fft.fftshift(np.fft.ifft2(clm.classifiers[0][36].f)))).view()\n",
    "#clm.view_expert_ensemble_widget()\n",
    "#clm.view_shape_models_widget()\n",
    "#clm.view_clm_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
